\documentclass[11pt]{report}
\usepackage[margin=0.5in]{geometry}
\usepackage{mathpazo}
\usepackage{amsmath}
\usepackage[colorlinks=true]{hyperref}
\usepackage{parskip}
\usepackage{tikz}
\usepackage{circuitikz}
\tikzstyle{Si}=[circle,draw=blue,fill=blue!50,thick]
\usepackage{listings}

\lstset{
	basicstyle=\ttfamily,
	numbers=left}

% Make lists condensed %
\usepackage{enumitem}
\setlist{nosep}

\begin{document}

\chapter{Security}\label{sec:topic-3}
\section{CIA Model}
\begin{itemize}
	\item Confidentiality
	\begin{itemize}
		\item Cryptography: encryption and decryption
		\item Access Control: some policy that limits access to certain users through personal ID, etc.
		\item Entity Authentication: ensure the ID of someone
		\begin{itemize}
			\item Something they have (token, key)
			\item Something they know (password)
			\item Something they are (fingerprint)
		\end{itemize}
		\item Physical security
	\end{itemize}
	\item Integrity
	\begin{itemize}
		\item Backups, checksums, ECC
		\item Cryptography: MAC over the message or a digital signature using a private key (symmetric or asymmetric)
	\end{itemize}
	\item Availability
\end{itemize}

\section{Partial Plaintext Attack}
Suppose transactions in a RFID system are encrypted as $C = Enc(k, M)$ for some 4-digit PIN $k$. Then, if a plaintext $M_0$ and its encryption $C_0$ is known, then an attacker need only try all $10^4$ PINs to compute $C' = Enc(k_i, M_0)$ until $C' = C_0$, at which point they have the PIN. This is much less than the $10^4 \cdot 2^{|M|}$ that would normally be required.

\section{Buffer Overflow}
\begin{lstlisting}
void main() {
	char line[10];
	gets(line);
}
\end{lstlisting}
Writing more than 10 bytes to \texttt{line} will begin to overwrite (in order):
\begin{itemize}
	\item The old Frame Pointer of the caller
	\item The return address
	\item Local variables of the caller
\end{itemize}
In performing a buffer overflow attack, the goal is to overwrite that return address to point into some code that the attacker has inserted.

\section{Spectre Attack}
\begin{lstlisting}
if (x < array1_size)
	y = array2[array1[x] * 4096]
\end{lstlisting}

\begin{itemize}
	\item If \texttt{x >= array1\_size} and \texttt{array1[x]} contains (for example) a secret key, then if the conditions are right the CPU will perform the memory access in line 2 while checking the condition
	\begin{itemize}
		\item Conditions
		\begin{itemize}
			\item \texttt{array1\_size} and \texttt{array2\_size[k*4096]} are uncached
			\item The key \texttt{k=array1[x]} is cached
			\item The branch predictor assumes that the condition will likely be true (e.g. if many previous iterations were true, this will likely happen for most branch predictors)
		\end{itemize}
		\item The \texttt{array2} access will miss while the branch is still being checked, and the value \texttt{array2[k*4096]} will be placed in cache even though the condition was false
		\begin{itemize}
			\item The time it takes to access this memory can be measured dependent on \texttt{k*4096}, from which the key k can be derived
		\end{itemize}
	\end{itemize}
\end{itemize}

\section{Trusted Platform Module}
\begin{itemize}
	\item Standard for a secure co-processor
	\item Principle: root of trust and transitive trust
	\begin{itemize}
		\item A layer X has a set D(X) called its \textbf{dependencies}
		\item $L \in D(X)$ if at least one of the following is true:
		\begin{itemize}
			\item L has RW access to the data of X
			\item L has W access to the code of X
		\end{itemize}
		\item Notation: $L \xleftarrow{} X$ means $L \in D(X)$
		\begin{itemize}
			\item $\xleftarrow{}$ is transitive
		\end{itemize}
	\end{itemize}
	\item Secure boot
	\begin{itemize}
		\item Each segment $X_i$ verifies $X_{i+1}$ before passing execution to it
	\end{itemize}
	\item Authentication Authority
	\begin{itemize}
		\item Each layer has an AA that holds the secret key used to authenticate items in the layer above it
		\item So X in layer J can call the AA in layer $k < J$ to generate auth data for itself that it can send to a remote party for verification
		\begin{itemize}
			\item E.g. a digital signature using a secret key where the public key is known by the remote
		\end{itemize}
	\end{itemize}
\end{itemize}

\chapter{Practical Cryptographic Schemes}\label{sec:topic-2}
\section{Pseudo-Random Sequence Generators (PRSG)}\label{sec:PRSG}
\subsection{FSRs}
A feedback shift register is an n-bit register with bits $a_{n-1}...a_0$ where at each cycle the last bit is determined according to a feedback function $f(a_{n-1} ... a_0) = f(\vec{a})$. $(a_{n-1} ... a_0) \xleftarrow{} (a_n ... a_1)$ where $a_n = f(\vec{a})$. The output bit is $a_0$. If you picture it with the LSB on the right, the output is on the right and the MSB gets loaded with the feedback function on the left in each cycle.

\subsection{LFSR}\label{sec:LFSR}
An LFSR (Linear FSR) is an FSR where $f(\vec{a}) = \sum_{i = 0}^{n-1} c_ia_i$ and $c_i \in \{0, 1\}$.

An m-sequence (or maximal length or pseudo noise sequence) is the output sequence with the maximal period for an LFSR. For an N-bit LFSR this is $2^N-1$ bits long. An LFSR generates an m-sequence as its output if and only if its \textbf{characteristic polynomial} is \textbf{primitive}. LFSRs have the following properties:

\begin{enumerate}
	\item All output sequences are either periodic or \textit{eventually} periodic
	\item The minimal polynomial of an LFSR sequence is a divisor of its characteristic polynomial
	\item For a given LFSR, all its m-sequences are \textit{shift-equivalent} and \textit{shift-distinct} to all m-sequences \textbf{not} generated by the LFSR (i.e. by other LFSRs)
\end{enumerate}

To explain property 2, think of it in the following way. An LFSR A has some characteristic polynomial $f(x)$. It generates a set of sequences depending on the initial conditions. Consider one such sequence $\{a_i\}$. The minimal polynomial of this sequence is the \textit{lowest degree} polynomial that, if it were the characteristic polynomial $h(x)$ of an LFSR B, B would also generate $\{a_i\}$. Property 2 states that $f(x) | h(x)$ (i.e. $f(x) = p(x)h(x)$ for some $p(x)$). As a corollary, if $f(x)$ is \textit{irreducible}, it is the minimal polynomial of all the sequences it generates. Furthermore, the minimal period of any sequence $f(x)$ generates is equal to its period.


\subsection{Galois Fields}
A Galois Field is a \textbf{field} with a finite number of elements. All such fields with $p^n$ elements for prime $p$ (denoted GF($p^n$)) are isomorphic to $\mathbb{Z}_{p^n}$. The binary field GF(2) is unique with the elements $\{0, 1\}$: the operations * and + are a logical AND and XOR respectively.

\subsection{Polynomials over GF(2)}
The feedback function of an LFSR can be represented as a polynomial with coefficients in GF(2):
\begin{equation}
	\sum_{i=0}^{n-1}c_ix_i \leftrightarrow t(x) = \sum_{i=0}^{n-1}c_ix^i
\end{equation}

Such a polynomial is \textbf{irreducible} if it cannot be written as the product of two (non-constant) polynomials. For example $x^2-2$ is irreducible over the integers but not over the reals.

Note that we can define the \textbf{period} of a polynomial as the \textit{minimum} $r$ such that $f(x) | x^r-1$. A polynomial is \textbf{primitive} if it is irreducible and its period is $2^N-1$.
Note that primitive polynomials must have a constant term, otherwise we could factor out an x and it would thus be reducible.

\subsection{Correlation}
The cross correlation of two N-length binary sequences is given by:

\begin{equation}
	C_{a, b}(\tau) = \sum_{i=0}^{N-1} (-1)^{a_i + b_{i+\tau}}
\end{equation}

It measures how similar a shifted version of $b$ is to $a$, and is thus a function over $\tau$. When $a=b$ this is also called the \textbf{autocorrelation}. If the lengths are not the same, we can use the following notation (where $M$ is the length of b:

\begin{equation}
	\label{eqn:general-cross-correlation}
	C_{a^T,b}(\tau) = \sum_{i=0}^{T-1}(-1)^{a_i + b_{(i + \tau) \mod M}}
\end{equation}

\textbf{Note that the operation $+$ in \autoref{eqn:general-cross-correlation} is XOR}


\subsection{Linear Span Attack}
The degree of the minimal polynomial of a sequence \textbf{a} of length N is called its \textbf{linear span}. In other words, the linear span of the sequence is the minimal $l$ such that an $l$-bit LFSR with initial state $(a_0, a_1, ...a_{l-1})$ generates the sequence $\{a_0 ... a_N\}$.

Given \textbf{a} can we make an LFSR that generates it? Obviously $f(x) = x^N-1$ would work since we just load the whole sequence into the LFSR. Using the \textbf{Berlekamp-Massey algorithm}, we can construct the \textit{minimal} LFSR that generates \textbf{a}. \textit{By definition}, this LFSR will have degree equal to the linear span of \textbf{a}, denoted LS(\textbf{a}).

As it turns out, the Berlekamp-Massey algorithm only needs 2LS(\textbf{a}) bits to perform the construction. This means that if \textbf{a} has linear span $n$, and $2n < N$, we can use the BM algorithm to construct the LFSR and then run it to generate the remaining $N-2n$ bits. This is called a linear span attack.

\subsection{Nonlinear Generators}
The goal here is to maintain the randomness and efficiency that comes from using m-sequences of LFSRs as random bitstreams, while \textit{increasing} the linear span to avoid a linear span attack. In \textbf{filtering sequence generators} we feed the full LFSR state into a nonlinear function that serves as the output bit. In \textbf{combinatorial sequence generators} we feed the output bits of M LFSRs into a nonlinear function that serves as the output. In \textbf{clock controlled} generators we use some clocked FSM to control which output bits of LFSR1 get fed into LFSR2 and then to the output.

\subsection{Correlation Attack}
When we use a \textbf{combinatorial sequence generator}, we can perform this attack to recover the initial states of the $m$ LFSRs. These states are assumed to be the keys (e.g. a stream cipher scheme could be to place the key in the LFSRs and then use the output stream as a one-time pad on the data).

Let the size of LFSR $i$ be $n_i$. Let the output stream of LFSR $i$ be denoted $X_i$. Note that $0 \le i < m$. We assume that we have the output stream of $Z$, it has length $T$ and is denoted $z$. We can perform exhaustive search by trying all possible initial states and seeing if it generates Z. The complexity of this is
\begin{equation}
	T_0 = \prod_{i=0}^{m-1} 2^{n_i}
\end{equation}

Under some assumptions, we can improve this:
\begin{itemize}
	\item $X_i$ are iid binary random variables
	\item $Z$ is a random variable whose value is $h(X_0, X_1, ... X_{m-1})$
	\item $I_C \subseteq \{X_0, ... X_{m-1}\} \neq \emptyset$ is a set of LFSRs which, based on the structure of the overall PRSG and function $h$, we know to be \textbf{correlated} with $Z$
\end{itemize}

This last point is important; based on Kerchoff's principle, the structure of the PRSG is usually known (including the sizes and polynomials of all the LFSRs and the function $h$). It is only the key that is secret.

The main idea here is that if we know that an LFSR is correlated with the output sequence, we can find its initial state \textit{independent} of the states of the other LFSRs. We will \textbf{still be doing an exhaustive search} on the LFSR (by trying every possible shift of its m-sequence), but only on one LFSR at a time.

The other key idea is that if we know $P[Z = 0 | X_k = t] > \frac{1}{2}$ or $P[Z = 1 | X_k = t] > \frac{1}{2}$ for $t \in \{0, 1\}$, then for a sufficiently large sample size, we can assume that the initial state of LFSR$_k$ that generates the \textbf{highest} correlation between $Z$ and $X_k$ is most likely to be the correct one. In particular, the probability that this assumption is wrong goes to zero as the size of the output sequence we are checking goes to infinity.

With this, the steps to perform a correlation attack are as follows:

\begin{enumerate}
	\item Write the truth table for the combining function $h$ with inputs $X_i$ (the 0th bit of LFSR$_i$)
	\item Use the formula $P[Z=i|X_j=k] = \frac{P[Z=i \land X_j=k]}{P[X_j=k]} = \frac{\#[Z=i \land X_j=k]}{\#[X_j=k]}$ (where \# means the number of times the event shows up in the truth table) to compute all the conditional probabilities
	\item Decide the set $I_C$ using step 2 ($X_i$ such that $Z$'s value has a skewed distribution relative to the value of $X_i$)
	\item For each element $X_i \in I_C$
	\begin{enumerate}
		% TODO: how
		\item Figure out the m-sequence for this LFSR and call it $x_i$ (recall that this is unique for a given LFSR up to shift-equivalence. see \autoref{sec:LFSR})
		\item Compute $C_{z^T, x_i}(\tau)$ using \autoref{eqn:general-cross-correlation} for $\tau \in [0, 2^{n_i})$  (i.e. to check every possible shift)
		\item Compute $\tau_0 = \text{argmax}_\tau |C_{z^T, x_i}(\tau)|$. Set the initial state of LFSR$_i$ to $x_i$ shifted by $\tau_0$
	\end{enumerate}
\end{enumerate}

The complexity of a correlation attack is given by

\begin{equation}
	T_1 = \sum_{i=0}^{m-1}2^{n_i}
\end{equation}


\section{Stream Ciphers}
A stream cipher uses a key to generate a pseudorandom sequence based on the methods described in \autoref{sec:PRSG}. This sequence is then XORed with the data (which may be of arbitrary size, hence stream instead of block) to encrypt it, analogously to the one-time pad system.

\subsection{Operation}
Stream ciphers consist of two phases: \textbf{key initialization} and \textbf{PRSG running}. During key initialization, the initial vector IV and key K are mixed. The result is then passed as the initial value to the PRSG which begins outputting a key stream that is XORed with the plaintext. The decryption scheme does the \textbf{exact same thing} and therefore needs the same IV.

\subsection{RC4}
RC4 is meant for efficient software implementation. The key-initialization algorithm (\textbf{KIA}) uses the key K to generate a permutation of all $n$-bit integers in memory. The PRSG increments a value $i$ and uses $S[S[i] + S[i + S[i]]]$ modulo $2^n-1$ as the output block (then swaps the values it used). Yes it seems like nonsense because it was, but since the system was kept secret for a while no one knew. It was used in WEP which caused a huge security issue when the code was leaked and attacks were discovered.

\section{Block Ciphers}

A block cipher involves an encryption and decryption algorithm. Each algorithm is essentially a function which is a one-to-one mapping of $n$-bit vectors. $n$ is called the block size. The important property (correctness) is that $D \circ E = \mathbb{1}$ (that is, encrypting then decrypting a plaintext gives back the original message).

Two principles in designing a block cipher:
\begin{itemize}
	\item \textbf{confusion}: the statistical relationship between plaintext and ciphertext should depend on many or all bits of the key
	\item \textbf{diffusion}: each plaintext bit should affect multiple ciphertext bits (small change in input $\xrightarrow{}$ large change in output)
\end{itemize}

Examples of block ciphers include DES and AES. Common structures used in them include
\begin{itemize}
	\item S-boxes: substitution - essentially tabularly represented functions that map input blocks to output blocks
	\item Feistel structures - an NLFSR
\end{itemize}

Another useful way to think of a $n$-bit block cipher is as the set of all permutations over all $2^n$ $n$-bit vectors, where the key selects which permutation to use.

\subsection{Block Cipher Modes}
We need some way to use the block cipher on data that may not be equal to the block size. Modes are the way to achieve this.

\subsubsection{Electronic Codebook (ECB)}
Divide the input into block-sized units and run the block cipher on each one individually

\subsubsection{Cipher Block Chaining (CBC)}
ECB causes two equivalent blocks to have the same output, so CBC instead uses the output of one block as an initialization vector to the next.

\subsubsection{Cipher Feedback (CFB)}
Use the key to generate a keystream from ciphertext bits. $K_i$ = $Enc_{K}(C_{i-1})$ gets XORed with the plaintext to produce $C_i = M_i \oplus K_i$. This turns the block cipher into a stream cipher.

\subsubsection{Counter Mode (CTR)}
In CFB, instead of using the ciphertext as the input to the block cipher, use a counter which gets incremented for each bit.

\section{Birthday Attacks}

Given a set $S$ of size $n$, the probability that two of $m$ randomly chosen elements (with replacement) are the same is given by \autoref{eqn:birthday}

\begin{equation}
	\label{eqn:birthday}
	\approx 1 - e^{\frac{-m^2}{2n}} \le \frac{m^2}{2n}
\end{equation}

The practical result is that if an element can take $N$ different values, you can expect it to take on the same value after observing about $\sqrt{N}$ instances. That is, for an $n$-bit value, we can expect a collision after $\sqrt{2^n} = 2^\frac{n}{2}$ instances.

\subsection{Time-Memory Tradeoff Attack}
Also known as a \textit{meet-in-the-middle} attack. Suppose we know that some system is encrypting a fixed plaintext $p$ using a randomly generated key $k$ of $n$ bits (for example if every transaction in some banking system starts with encrypting 'hello'). Then we can choose $2^{\frac{n}{2}}$ random keys and store the encryption of $p$ under each of them. That is, we can compute the set $T = \{(k_i, Enc_{k_i}(p)) \ | \ i \in [0, 2^{\frac{n}{2}})\}$. We can expect to observe a key $k$ for which we have already precomputed $Enc_{k_i}(p)$ to be used after observing about $2^{\frac{n}{2}}$ transactions.

That is, we have traded off the memory of storing $T$ for the time of observing another $2^{\frac{n}{2}}$ transactions, and the time complexity becomes $2^{\frac{n}{2}}$.

\section{Security Models}
\subsection{Chosen Plaintext Attack (CPA)}
An attacker is given access to an encryption oracle that will provide $Enc(p)$ for any plaintext it is given. The goal of the attacker is to figure out which of two plaintexts $m_0$ and $m_1$ corresponds to a given ciphertext $c$. Note that since the attacker could ask for $Enc(p)$, no deterministic encryption can be CPA secure.

With CBC for example, any further queries of $Enc(m_0)$ and $Enc(m_1)$ will be different since the oracle holds some state.

\section{Hash Functions}
Three important properties of a hash function:

\begin{itemize}
	\item \textbf{Collision Resistance}: Finding $x$, $y$ s.t. $h(x) = h(y)$ is difficult
	\item \textbf{Second pre-image resistance}: Given $x$, finding $y$ s.t. $h(x) = h(y)$ is difficult
	\item \textbf{Pre-image resistance}: Given $z$, finding $x$ s.t. $h(x) = z$ is difficult
\end{itemize}

Note that satisfying the first property implies the other two are satisfied. The reverse is not true.

A hash function maps $n$ bits to $m$ bits where $n > m$, and thus multiple values may map to the same thing. The design of hash functions is thus similar to block ciphers but with the requirement of a one-to-one mapping being relaxed.


\section{Message Authentication Code (MAC)}
A MAC is used in symmetric-key cryptography to verify that a message was sent by someone who knows the key $k$. There are many ways to implement it using keyed hash functions, block ciphers, or authenticated encryption. The key property is \textbf{unforgeability} - even if an attacker has access to an oracle that produces $t = MAC_{k}(m)$, it cannot produce $(m, t)$ such that Verif$(m,t) = 1$ and $m$ was not part of a query to the oracle.

\section{Public Key Cryptography}
\subsection{One-Way Functions}
A fundamental concept in public key cryptography is that of a one-way function. A function is 'one-way' if it is 'easy' to compute its output, but difficult to compute the input given its output. A \textit{trapdoor} one-way function is a one-way function that, if one knows some special piece of information, makes it easy to compute the input given the output.


\subsection{Diffie-Hellman Key Exchange}
The setting for Diffie-Hellman key exchange is a finite field $\mathbb{F}_p$ with $p$ elements. $g$ is a 'primitive element' of the field; that is, each nonzero element of $\mathbb{F}_p$ can be written as $g^i$ for some integer $i$. Note that in the finite field, the addition and multiplication operations are done modulo $p$ but this will often be omitted for brevity. This is equivalent to:

\begin{align}
	\label{eqn:primitivity-1}
	g^{p-1} &= 1\\
	\label{eqn:primitivity-2}
	g^{i} &\neq 1 \ \ \ \ \ \ \forall \ \ 1 \le i < p - 1
\end{align}

Each user $i$ has a keypair $(i, g^i)$. By the discrete log problem, $i$ is difficult to compute given $g^i$ (but not vice versa). Two users $a$ and $b$ can compute a shared key $k$ by sending eachother their public key. Then, user $a$ can compute $g^{ab} = (g^b)^a$ using their private key and user $b$ can do the same. Then the shared key is $g^{ab}$ which can be used to perform symmetric encryption/authentication.

\subsubsection{Lagrange's Theorem}
\autoref{eqn:primitivity-2} requires us to check $p-1$ values. Instead, we can check if an element is primitive using Lagrange's theorem. Simply put, an element $a$ is primitive if $a^{p-1}=1$ and $a^{q} \neq 1$ for all prime factors $q$ of $p-1$.

For example, if $p=47$ then since $(p-1) = 46 = 23\cdot2$ we only need to check the following to verify if $a$ is primitive:

\begin{align*}
	a^{p-1} &= a^{46} = 1\\
	a^{23} &\neq 1\\
	a^2 &\neq 1\\
\end{align*}

\subsection{RSA}
RSA relies on the difficulty of factoring large numbers. $\phi(n)$ is the Euler totient function and is equal to the number of integers up to $n$ that are relatively prime to it (two numbers $a, b$ are relatively prime if $\text{gcd}(a,b) = 1$). Obviously, $\phi(p) = p-1$ for prime numbers $p$ (i.e. all except itself). It also turns out that for the product of two prime numbers $p, q$: $\phi(p\cdot q) = (p-1)(q-1)$.

\subsubsection{Key Generation}

The process to generate the public and private keypair is as follows:

\begin{enumerate}
	\item Generate large primes $p$ and $q$
	\item Compute $n = pq$ and $\phi(n) = (p-1)(q-1)$
	\item Select the \textbf{public exponent} $e \in [1, \phi(n)-1]$ such that $e$ is relatively prime to $\phi(n)$
	\item Compute $d = e^{-1} \mod{\phi(n)}$
\end{enumerate}

The \textbf{public key} is the tuple $(n, e)$. The \textbf{private key} is the tuple $(d, p, q)$.

Anyone who knows $n, e$ cannot easily find $\phi(n)$ and thus can't compute $d$.

\subsubsection{Encryption}
A plaintext $m < n$ can be encrypted as $c = m^e \mod{n}$ using info from the public key.

\subsubsection{Decryption}
A ciphertext $c$ can be decrypted as $m = c^d \mod{n}$.

\subsubsection{Signature (RSA-DSA)}
A message can be signed by computing $h(m)^d \mod{n}$ for some hash function $h$ that outputs a suitably sized value. This can be verified by computing $s^e \mod{n}$ and comparing it with $h(m)$.

\subsubsection{Computing d}
 We use the extended euclidean algorithm to find $d = e^{-1}\mod{\phi(n)}$ given $e$ and $\phi(n)$. It gives us $d, k$ such that $de + k\phi(n) = 1$ and this gives us $d$.

\section{Digital Signature Standard (DSS)}
This scheme only provides signatures. It has the following elements:

\begin{enumerate}
	\item $p$ a (large) prime number
	\item $q$ a prime factor of $(p-1)$
	\item $g \in \mathbb{F}_p$ with $\text{ord}(g) = q$
	\item $h$ a cryptographic hash function
\end{enumerate}


\subsection{Keypair}
Signer selects some $x \in [1, q-1]$ as the private key. $y = g^x$ is the public key.

\subsection{Signature}
The signer performs the following for each message to sign:

\begin{enumerate}
	\item Randomly select $k \in [1, q-1]$
	\item Compute $r = g^k$
	\item Solve for $s$ in the signing equation (\autoref{eqn:dss-signing-eqn})
\end{enumerate}

\begin{equation}
	\label{eqn:dss-signing-eqn}
	h(m) \equiv xr + ks \mod{q}
\end{equation}

The signature is provided as the tuple $(r, s)$. Note how steps 1 and 2 reflect the keygen process. Step 3 requires the usage of the extended euclidean algorithm.

\subsection{Verification}
The verifier does the following:

\begin{enumerate}
	\item Compute $u = h(m)s^{-1} \mod{q}$ and $v = -rs^{-1}\mod{q}$
	\item Compute $w = (g^uy^v \mod{p})\mod{q}$
	\item Accept if $w = r$
\end{enumerate}

This works because of the following. Starting with \autoref{eqn:dss-signing-eqn} (and recalling that $r = g^k$):

\begin{align*}
	k &= h(m)s^{-1} - xrs^{-1}\\
	g^k &= g^{h(m)s^{-1} - xrs^{-1}}\\
	r &= g^{u}(g^x)^{-rs^{-1}}\\
	r &= g^u y^v\\
\end{align*}

% TODO
\section{Elliptic Curve Cryptography}

An elliptic curve is a set of points $(x, y) \in F$ that satisfy some cubic equation. We can define an addition operation on this set of points to form a \textbf{group}: to add two points $P$ and $Q$ draw a line between them and set $R = (x, -y)$ where $(x, y)$ is the third point that intersects the curve (note that the $y$ coordinate is flipped). If $P=Q$ then the line connecting them is just the tangent at $P$.

\subsection{ECC Finite Fields}
We restrict our attention to points where $x, y \in \mathbb{F}_p$. Given parameters $(a, b, p)$ we can solve for all such points on the curve as follows:

\begin{enumerate}
	\item Compute all the 'quadratic residues' in $\mathbb{F}_p$. That is, the set $QR = \{i | \exists y \in \mathbb{F}_p \text{ s.t. } i = y^2 \mod{p} \}$
	\item For all $x \in \mathbb{F}_p$, compute $x^3 + ax + b$ and see if $x \in QR$. If so, then $(x, y)$ is a point where $y^2 = x^3 + ax + b$.
\end{enumerate}

The group formed by these points is \textbf{cyclic}, that is every element is a generator. Do note that there is technically also a 'point at infinity' denoted $\infty$ or $\mathcal{O}$ which is not a generator which acts as the additive identity.

\subsection{Keypair}
A curve and field is selected, along with an arbitrary generator point $P$. The \textbf{private key} is a random integer $d$ where $0 < d < q$. The \textbf{public key} is $Q = dP$.

\subsection{EC-DH}
We can compute a shared diffie-hellman secret using $d_AQ_B = d_BQ_A = (d_Ad_B)P$.


\section{Hash-Chain Based Authentication}
Hashing is much faster than verifying a signature in a public-key system. The problem we want to solve is how to authenticate $n$ messages $x_0 ... x_{n-1}$ without having to sign each one.


\subsection{Hash Chains}
A hash chain is a building block that can be used to solve the authentication problem. In a hash chain, we select a value $y$ and compute $k_i = h^{n-i}(y)$ for $i \in [0, n)$ (we start by computing $k_{n-1}$). Then we sign $k_0 = h^{n}(y)$ using a private key of some sort, i.e. $\text{Sig}_{A}(k_0)$. The hash chain is given by the tuple:

\begin{equation}
	(\text{Sig}_{A}(k_0), k_0, ..., k_{n-1})
\end{equation}

Thus all we need to do to verify is first verify the signature $\text{Sig}_{A}(k_0)$. Then we know $k_0$ is correct. Then we can verify $k_1$ by computing $h(k_1)$ which should be equal to $k_0$ (assuming $h$ is secure), and we can continue this process. Thus we only require 1 signature verification and $n-1$ hashes to verify the whole chain, which is much better than $n$ signature verifications.


\subsection{Basic Hash Chain Message Authentication}
The first approach to solving the authentication problem is as follows. Suppose the server is $A$ and the receiver is $B$. $B$ would like to receive messages $x_1 ... x_n$ and ensure they are authenticated. $A$ starts by generating an $n+1$-length hash chain (\textbf{not} $n$). It then sends $B$ the message $(k_0, \text{Sig}_{A}(k_0))$, which $B$ can verify using $A$'s public key. $A$ then sends the message $(x_1, \text{MAC}(k_1, x_1))$, then sends $k_1$. $B$ first hashes this latter value to check that $h(k_1) = k_0$ so it knows $k_1$ is the correct value. Then $B$ can authenticate $x_1$ using $\text{MAC}(k_1, x_1)$. $A$ then sends $(x_2, \text{MAX}(k_2, x_2))$ which can be verified with $k_1$, and so on and so forth. At any point, $B$ only needs to hold on to $k_0$ and $k_{i-1}$ to verify $x_i$.

\subsection{Hash Chain One-Time Password Authentication}
Another application of hash chains is for providing passwords to access some system. Instead of using the same long-term password, a user pre-generates a hash chain $k_0 ... k_n$ and stores $k_0$ on the remote system in some secure manner. On the $i$-th access, they can use $k_i$ as the password ($k_0$ is never a password). The system will check $k_{i-1} = h(k_i)$ and accept the password if so. This is only good for $n-1$ accesses.

\subsection{Merkle Trees}
Merkle trees solve a slightly different problem. In this problem, there are $n$ messages but they are not 'sequenced' - the system must be able to authenticate any randomly chosen message $x_i$. The messages may be generated by one party or by $n$ different parties (each contributing one). %TODO does A say whetehr x_i is correct or does it provide info to figure this out?

A Merkle tree is a complete binary tree where there are $n$ leaves ordered left to right with 'labels' $h(x_i)$. Non-leaf nodes are labeled by $h(L || R)$ where $L$ is the label of the left child and $R$ the label of the right child ($||$ denotes concatenation). The root is called $r$.

An example (which seems to be the implicit one described in the lectures and textbook) is as follows. We have a \textbf{data owner} $B$ who produces $(x_1, ..., x_n)$. They send this along with the full Merkle tree to a \textbf{server} $A$. They also publish and sign the root value. $B$ wants \textbf{clients} $C$ to be able to get any $x_i$ they want from $A$ and be assured that it is authentic (e.g. the $x_i$ are database entries). When $C$ requests to authenticate $x_i$, $A$ sends the values on the authentication path (or \textit{co-path}) for $x_i$ which consists of all the siblings on the path from the root to $h(x_i)$. The client $C$ can use these values to reconstruct the root value. If the root value it reconstructs is the same as the (signed and verified) value published by $B$, $C$ can be assured that $x_i$ is correct.

\section{Blockchain}
In a digital currency system, we can form \textbf{transactions} as tuples $(pk_A, pk_B, amt)$ where users are identified by their public keys. Transactions are signed by the sender. If it is valid (signature and amount) according to the current state of the blockchain, the transaction will be appended to the blockchain.

To prevent double-spending, nodes are awarded for computing a \textit{nonce} (number used once) such that the value in \autoref{eqn:blockchain} has some special bit pattern (e.g. $k$ zeros at the start). Thus there is an incentive to verify the earliest valid transaction. The node that computes the nonce publishes it and is rewarded if it is correct and the blockchain is then updated.

\begin{equation}
	\label{eqn:blockchain}
	h(h(B_{prev})||pk_A||pk_B||nonce)
\end{equation}

Each block contains multiple transactions, and their contents can be validated using a Merkle tree. The storage of nodes in the tree is distributed.


\chapter{Network and Wireless Security}\label{sec:topic-3}

\section{Challenge-Response Authentication}
The goal of authentication is for a party $A$ to ensure that the party it is communicating with (also called the \textit{peer}) is $B$ and not someone else. The fundamental building block of authentication protocols discussed in this course is the challenge-response method. It can be used with both symmetric and asymmetric (public + private) key systems.

In the symmetric case, parties $A$ and $B$ share a key $K_{AB}$. For $A$ to verify that its peer is $B$, it issues a random message $Ch$ called the \textbf{challenge}. The peer must compute $\text{MAC}(K_{AB},Ch)$ - for a secure MAC only parties that know $K_{AB}$ (which, by assumption, is only $A$ and $B$) can do this. $A$ can then check the result against its own computation of $\text{MAC}(K_{AB},Ch)$ and, if it is correct, trust the peer to be $B$. The challenge must be randomly generated to prevent a replay attack.

In the asymmetric case, $A$ knows $B$'s public key. $A$ sends a challenge $Ch$ to the peer, and the peer must compute $Sig_{S_B}(Ch)$ which can only be computed using $B$'s private key $S_B$. $A$ can then use the known public key to verify the signature and trust the peer.

To unify the two cases with notation, $[\vec{U}]_B$ will be used to denote an authenticated message where:

$$\vec{U} = (U_1, ..., U_n)$$

In the symmetric case, $[\vec{U}]_B = \text{MAC}(K_B, U_1, ..., U_n)$ where $K_B$ is the symmetric key shared with the receiving party. In the asymmetric case, $[\vec{U}]_B = Sig_{S_B}(U_1, ..., U_n)$.

\section{Public Key Infrastructure (PKI)}
The problem with asymmetric key systems (e.g. RSA) is that anyone can generate a valid public-private keypair. We need some way for a party $A$ to ensure that a given public key is actually the public key of an entity $B$ and not one generated by the adversary $E$.

This can be accomplished by having a \textbf{Certificate Authority} (CA) whose public key is known (usually installed on the device). The CA can create \textbf{certificates} which essentially are signatures over the tuple $(PK_{B}, ID_{B})$ where $PK_B$ is the public key of $B$ and $ID_B$ is some string corresponding to the identity of $B$. The signature can be verified using the known public key of the CA.

It would be infeasible to have one universal CA that signs everyone's public keys. Instead, a \textbf{root CA} creates certificates for subordinate CAs, which in turn may sign public keys or other CAs. This forms a \textbf{certificate chain} for any given public key. To verify a certificate chain, we first verify the 'lowest level' certificate (i.e. a direct signature of an entity's public key by a CA). We then verify the certificate of the lowest level CA, then the next CA, and so on until we reach the root CA whose public key is known.

\section{Mutual Authentication and Key Establishment}
This section covers some general concepts that are used throughout the rest of this chapter. The goal of this chapter is to design Authentication and Key Establishment (AKE) protocols to generate keys for all the parties and ensure that they are authenticated and then use techniques from \autoref{sec:topic-2} to secure communications.

A key establishment protocol allows two or more parties to decide on cryptographic keys to use in securing a communication channel between them. There are two types of keys that will be used in key establishment protocols:

\begin{itemize}
	\item Long-term keys: keys that exist before the protocol
	\item Session keys: keys that are established as a result of the protocol
\end{itemize}

For simplicity, we can assume that the goal of a protocol is to establish just one session key - one can use a \textbf{Key Derivation Function} (KDF) to generate more keys when needed. There are two main types of AKE protocols:

\begin{itemize}
	\item Key \textbf{transport}: one party generates the session key which is then transferred to the other parties
	\item Key \textbf{agreement}: the session key is a function of inputs from all parties
\end{itemize}

We may also have a method for \textbf{key confirmation} to ensure that two parties are indeed using the correct key.

\section{Internet Key Exchange (IKE)}
IKE is used to establish \textbf{Security Associations} (SA) between two IP hosts before IPSec communications begin. A security association includes a set of cryptographic algorithms each of which can be one of the following:

\begin{enumerate}
	\item A Diffie-Hellman group ($\mathbb{F_p}$, elliptic curve, etc.)
	\item A pseudorandom function (PRF)
	\item An integrity protection mechanism (e.g. a MAC)
	\item An encryption algorithm
\end{enumerate}

It also contains the data and/or parameters used in each of these algorithms (keys, elliptic curve params, etc.).

A simplistic version of IKE was given in the lectures under the name 'Protocol C'. It operates as follows. Assume that there are two parties $A$ and $B$ that wish to agree on keys and that \textbf{ciphersuite negotiation} has already occurred and that the chosen Diffie-Hellman group was $\mathbb{F}_p$.


\begin{enumerate}
	\item A sends an \textit{initiation} message containing
	\begin{itemize}
		\item $R_A$ a random value which allows for confirmation of the key that will be generated
		\item $g^a$ its public key to be used in DH key establishment
	\end{itemize}
	\item B may optionally verify A's public key using a certificate. B does the following:
	\begin{itemize}
		\item Generates a random value $R_B$ to be used for key confirmation
		\item Computes $\alpha = (g^a)^b$ as the shared DH secret, and a key $K_\alpha = \text{KDF}(\alpha)$ from it. We may not be able to use $\alpha$ as the key directly since it may not be large enough so KDF is often a PRSG that generates enough bits for a key using $\alpha$
	\end{itemize}
	\item B then sends a response containing
	\begin{itemize}
		\item $ID_B$ containing its identity so that A may authenticate it
		\item $R_B$
		\item $Sig_{b}(R_B, R_A, g^a, g^b)$ which authenticates B as the owner of the keypair $(b, g^b)$. It prevents a replay attack by using $R_B$ and $R_A$.
		\item $\text{MAC}(K_\alpha, R_A, ID_B)$ which confirms the key $K_\alpha$ and prevents a replay attack using $R_A$.
	\end{itemize}
	\item A then authenticates B's identity using a CA. Then it computes $K_\alpha$ using B's public key, verifies the signature in B's response and confirms the key using the MAC from B's response. Finally, it sends a response containing
	\begin{itemize}
		\item $ID_A$ containing its identity (only sent now to protect privacy if A is a user)
		\item $Sig_{a}(R_B, R_A, g^a, g^b)$ which authenticates A as the owner of the keypair $(a, g^a)$ and prevents a replay attack by using $R_B$ and $R_A$
		\item $\text{MAC}(K_\alpha, R_B, ID_B)$ which confirms the key $K_\alpha$ and prevents a replay attack using $R_B$.
	\end{itemize}
\end{enumerate}

\subsection{Resource Exhaustion Attack}
An attacker can spam someone with IKE requests with forged IP addresses which wastes a lot of CPU in keygen etc. As a countermeasure, we can require a cookie containing the claimed IP address and its hashed value. If the initiator can send it back then the IP address is correct and thus not forged.

\section{IPSec}
IPSec enables the protection of IP packets. There are two modes. In \textbf{transport} mode, the SA established by IKE corresponds to the sender and receiver in the IP packet - routing is done using the IP header which is then stripped and the IPSec header/payload is processed by the receiver. In \textbf{tunnel} mode, the SA established by IKE corresponds to two nodes that sit between the actual sender and receiver (e.g. security gateways in an enterprise network) - routing is done normally except the IPSec header/payload is inserted at the inner two nodes.

If IPSec is used, the IP headers also include some data known as a \textbf{Security Parameter Index} (SPI) to indicate which SA should be used to process the packet.

IPSec consists of two mechanisms: an \textbf{Authentication Header} (AH) and \textbf{Encapsulating Security Protocol} (ESP). Either one may be used, or even both.

\subsection{Authentication Header (AH)}
The authentication header only provides message integrity and anti-replay. It does so by computing an \textbf{Integrity Check Value} (ICV) using a MAC over fields in the IP packet. The shared key to use in the MAC was established by IKE. Since some fields in an IP packet (e.g. TTL) may change as they are routed, the ICV is only computed over \textit{immutable} fields in the packet. This value is then inserted between the IP header and payload. A monotonically increasing sequence number is used to prevent replay attacks.

\subsection{Encapsulating Security Protocol (ESP)}
ESP can provide both confidentiality and integrity. The correct way to do this is to \textit{encrypt then authenticate}. The payload of the IP packet is encrypted, and an ICV is computed over the payload plus the SPI and sequence number. There may also be an initialization vector (IV) value if it is required by the encryption algorithm. The ICV is appended to the end of the encrypted data.

% TODO: 414 in slides
\section{TLS}

TLS is a protocol for establishing a secure connection between a \textit{client} and \textit{server} at the transport layer. It is itself a layered protocol consisting of a record protocol and 4 client protocols. The record protocol handles the delivery of messages from the client protocols (segmentation, compression, authentication, encryption) and sits on top of some transmission-layer protocol (e.g. TCP). The four client protocols are the handshake, cipher-spec change, alert, and application data protocols. We only discuss the record layer and handshake protocols in detail, the others are fairly straightforward.

\subsection{Handshake Protocol}
A cipher suite is negotiated and server authentication is performed. There is an option to have client authentication, but it is not strictly necessary. The initiator begins by sending a \texttt{ClientHello} message containing its supported ciphersuites and a random number to be used in key establishment. The server responds with a \texttt{ServerHello} containing the selected ciphersuite which contains (usually):

\begin{itemize}
	\item A key establishment scheme which is one of
	\begin{itemize}
		\item Diffie-Hellman: the client and server use their long-term DH keypairs (the server's public key has been signed by a CA)
		\item \textbf{Ephemeral} Diffie-Hellman: the client and server will generate fresh DH keypairs for this session
		\item RSA
	\end{itemize}
	\item A digital signature algorithm
	\item A symmetric-key based encryption scheme
	\item A hash function
\end{itemize}

The server also sends a \texttt{ServerKeyExchange} message containing the ephemeral Diffie-Hellman key if DHE was selected in the ciphersuite. The client then responds with \texttt{ClientKeyExchange} containing material for shared-key establishment (i.e. $g^a$ if DH or DHE is being used or an encrypted secret in RSA) and authentication material if client auth is being used.

The client and server can then generate a \textbf{pre-master secret} which is some shared secret (e.g. $g^{ab}$) using the \texttt{ServerKeyExchange} and \texttt{ClientKeyExchange} data. They combine this with the client and server nonces from \texttt{ClientHello} and \texttt{ServerHello} to generate the \textbf{master secret}.

The client and server use the master secret to generate 4 keys (enc and auth for each direction of communication). They each send a final \texttt{ChangeCipherSpec} message (containing key confirmation values) before beginning to exchange encrypted application data.

\subsection{Record Layer Protocol}
The record layer protocol uses the established ciphersuites and keys to authenticate and encrypt/decrypt the application data. It can do either on its own or combine them with \textit{authenticated encryption} (e.g. Galois Counter Mode).

\section{Access Authentication and Wireless Security}
An access authentication protocol allows an \textit{access node} to gain access to some service (e.g. a network). It is separated from the discussion of authentication since there are usually more than two parties involved and thus the trust model is slightly different.

\subsection{4G-LTE Protection}
The algorithm discussed in the course is \textbf{Evolved Encryption/Integrity Algorithm 1} (EEA1 and EIA1). They both use a stream cipher called \textbf{Snow 3G}, where integrity is performed similar to Galois Counter Mode.

\subsubsection{Snow 3G}
Snow 3G is a PRSG that consists of an LFSR and a 3-bit FSM which, when loaded with some initial state, run for 32 cycles and then fed into a linear function that serves as the output random bitstream.

\subsubsection{GHASH}
We will now be working with \textit{extension fields} where arithmetic is performed with polynomials modulo some irreducible polynomial $f(x)$ - when we get a polynomial with degree higher than $k$ for a $\text{GF}(2^k)$ field we will find its remainder when divided by $f(x)$ to get the result.

GHASH evaluates the polynomial $\sum_{i}^n M_iH^{n-i}$ for some polynomial $H$ and message blocks $M_i$. It is similar to CBC except done with polynomial multiplication:

\begin{align*}
	Y_1 &= M_1 H \\
	Y_i &= (M_i + Y_{i-1})H \ \ \ i > 1\\
\end{align*}

The value $H$ usually comes from the encryption of $0$ using AES under the given key. The computation can be done quicker with the table given in class. To use the table, we can replace bitstrings with $\alpha^n$ where $n$ is the value in the 'log' column and vice versa. This allows us to use properties of exponentials to reduce the work we have to do in reducing the equation. For example, when $f(x) = \alpha^4 + \alpha + 1$ in $\text{GF}(2^4)$ we can use the table to do the multiplication $1100 \cdot 1111$ (little endian) as follows:

\begin{align*}
	1100 \cdot 1111 &= \alpha^4 \cdot \alpha^{12} \\
					&= \alpha \cdot \alpha^{15} \\
					&= \alpha \\
					&= 0100
\end{align*}
Where the first step uses the table to turn bitstrings into powers of $\alpha$, and the second last step uses the table to write $\alpha^{15} = 1$.

\subsubsection{GHASH Forgery}
Since GHASH is linear for a given $H$, we can forge the GHASH tag for the XOR of two messages by XORing their GHASH tags \textbf{if H is reused}. We can force H to be reused by forcing IV reuse - recall that H is taken as the encryption of the 0 vector under a given key.


\subsubsection{EIA1}
EIA1 is the integrity algorithm used in 4G-LTE. It is a specific way of using GHASH to provide integrity for messages in the network. It uses Snow-3G to generate some random bits $(P, Q, OTP)$ and computes the message integrity code (MIC) as

\begin{equation}
	\text{MIC}(M) = \text{GHASH}(M, P)\cdot Q + (\text{LENGTH}\cdot Q + OTP)
\end{equation}

\subsection{IEEE 802.11}
Originally designed as just the first hop for a device to access the Internet. There are two modes: \textbf{infrastructure} and \textbf{ad-hoc}. The former involves an \textbf{Access Point} (AP) that provides access to a wired network for multiple \textbf{Stations} (STA) while the latter is a node-to-node connection between stations.

\subsubsection{Wired Equivalent Privacy (WEP)}

WEP uses a keystream generated using RC4 to encrypt packets of data. An AP can authenticate a STA by sending a challenge and receiving $K_s \oplus Ch$ where $K_s$ is the current key generated by the keystream of RC4.

An integrity value is computed using Cyclic Redundancy Check. For packets $P$ of size $t$ there is a $t-1$-degree polynomial $f(x)$. The integrity check value (ICV) is computed as the remainder of $P$ when divided by $f$.

Some flaws of WEP:

\begin{enumerate}
	\item Short IV causes the keystream to collide - only 24 bits go into the RC4 so we can expect a repeat every $2^{12} = 4096$ packets. This allows us to recover $P_1 \oplus P_2$ for two packets $P_i$ encrypted with the same key
	\item WEP uses CRC for integrity which does not actually depend on a key and can thus be forged
	\item WEP authentication gives out the keystream. If the challenge is known, $K_s$ can be computed from $Ch \oplus (Ch \oplus K_s)$ thus exposing the keystream
\end{enumerate}

\subsubsection{IEEE 802.1x 4-Way Handshake}
A \textbf{Supplicant} and \textbf{Authenticator} implicitly authenticate eachother and establish shared keys which are then used to derive further keys for authentication and encryption

\subsubsection{CCMP}
Instead of WEP encryption, CCMP uses AES in CCM mode which is an authenticated encryption mode.

\subsubsection{GCMP}
Like CCMP but uses Galois Counter Mode instead.

\chapter{Web Security}

\section{HTTPS}
HTTPS is HTTP executed over TLS. As such, it requires a \textbf{public-key infrastructure} (PKI) that can produce certificate chains for various websites.

\section{Sessions and Cookies}
Since HTTP is stateless, cookies can be used to establish sessions. This may be vulnerable to session hijacking such as through replay or cross-site scripting (XSS) attacks.

\section{Email Security}
\subsection{Pretty Good Privacy (PGP)}
PGP is based on a ring of trust model. A user A obtains the public key of party B by asking a party C that it already trusts.

\section{Password Hashing}
How should passwords be stored securely on a server? The first answer might be hashing since it is hard to reverse but still allows the comparison to the pre-image. However, this enables the possibility of a time-memory tradeoff attack which precomputes the hash for many common passwords known as \textbf{rainbow tables}.

Instead we should \textbf{salt} the passwords before hashing them. That is, we compute a tag as $tag = h(password || salt)$ and store $(tag, salt)$ where $salt$ is a randomly generated bitstring. This increases the complexity of the TMT attack significantly (proportional to the salt size). We may also want the hash function to be more computationally complex than the ones we have already considered, as the speed is not important but slows down attackers.

\end{document}
